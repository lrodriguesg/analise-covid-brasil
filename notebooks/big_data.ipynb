{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum as sum_col, avg, when, to_date, year, month, dayofweek, lit\n",
    "from pyspark.sql.types import IntegerType, DoubleType, StringType, DateType\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BigData\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\", \"true\") \\\n",
    "    .config(\"spark.memory.offHeap.size\", \"5g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos para os arquivos\n",
    "base_path = \"datasets_raw/HIST_PAINEL_COVIDBR_31mai2025/\"\n",
    "\n",
    "df_2021_p1 = spark.read.csv(base_path + \"HIST_PAINEL_COVIDBR_2021_Parte1_31mai2025.csv\", header=True, inferSchema=True, sep=';', encoding='ISO-8859-1')\n",
    "df_2021_p2 = spark.read.csv(base_path + \"HIST_PAINEL_COVIDBR_2021_Parte2_31mai2025.csv\", header=True, inferSchema=True, sep=';', encoding='ISO-8859-1')\n",
    "df_2022_p1 = spark.read.csv(base_path + \"HIST_PAINEL_COVIDBR_2022_Parte1_31mai2025.csv\", header=True, inferSchema=True, sep=';', encoding='ISO-8859-1')\n",
    "df_2022_p2 = spark.read.csv(base_path + \"HIST_PAINEL_COVIDBR_2022_Parte2_31mai2025.csv\", header=True, inferSchema=True, sep=';', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[regiao: string, estado: string, municipio: string, coduf: int, codmun: int, codRegiaoSaude: int, nomeRegiaoSaude: string, data: date, semanaEpi: int, populacaoTCU2019: int, casosAcumulado: double, casosNovos: int, obitosAcumulado: int, obitosNovos: int, Recuperadosnovos: int, emAcompanhamentoNovos: int, interior/metropolitana: int]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unir todos os DataFrames\n",
    "df_raw = df_2022_p1.unionByName(df_2022_p2, allowMissingColumns=True) \\\n",
    "                   .unionByName(df_2021_p1, allowMissingColumns=True) \\\n",
    "                   .unionByName(df_2021_p2, allowMissingColumns=True)\n",
    "\n",
    "df_raw.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- regiao: string (nullable = true)\n",
      " |-- estado: string (nullable = true)\n",
      " |-- municipio: string (nullable = true)\n",
      " |-- coduf: integer (nullable = true)\n",
      " |-- codmun: integer (nullable = true)\n",
      " |-- codRegiaoSaude: integer (nullable = true)\n",
      " |-- nomeRegiaoSaude: string (nullable = true)\n",
      " |-- data: date (nullable = true)\n",
      " |-- semanaEpi: integer (nullable = true)\n",
      " |-- populacaoTCU2019: integer (nullable = true)\n",
      " |-- casosAcumulado: double (nullable = true)\n",
      " |-- casosNovos: integer (nullable = true)\n",
      " |-- obitosAcumulado: integer (nullable = true)\n",
      " |-- obitosNovos: integer (nullable = true)\n",
      " |-- Recuperadosnovos: integer (nullable = true)\n",
      " |-- emAcompanhamentoNovos: integer (nullable = true)\n",
      " |-- interior/metropolitana: integer (nullable = true)\n",
      "\n",
      "Número total de linhas no DataFrame combinado: 4101870\n"
     ]
    }
   ],
   "source": [
    "df_raw.printSchema()\n",
    "print(f\"Número total de linhas no DataFrame combinado: {df_raw.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- regiao: string (nullable = true)\n",
      " |-- estado: string (nullable = true)\n",
      " |-- municipio: string (nullable = true)\n",
      " |-- coduf: integer (nullable = true)\n",
      " |-- codmun: integer (nullable = true)\n",
      " |-- codRegiaoSaude: integer (nullable = true)\n",
      " |-- nomeRegiaoSaude: string (nullable = true)\n",
      " |-- data: date (nullable = true)\n",
      " |-- semanaEpi: integer (nullable = true)\n",
      " |-- populacaoTCU2019: integer (nullable = true)\n",
      " |-- casosAcumulado: double (nullable = true)\n",
      " |-- casosNovos: integer (nullable = true)\n",
      " |-- obitosAcumulado: integer (nullable = true)\n",
      " |-- obitosNovos: integer (nullable = true)\n",
      " |-- Recuperadosnovos: integer (nullable = true)\n",
      " |-- emAcompanhamentoNovos: integer (nullable = true)\n",
      " |-- interior/metropolitana: integer (nullable = true)\n",
      " |-- ano_data: integer (nullable = true)\n",
      " |-- mes_data: integer (nullable = true)\n",
      " |-- dia_semana_num: integer (nullable = true)\n",
      " |-- dia_semana_nome: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df_raw.filter(col(\"regiao\") != \"Brasil\") \\\n",
    "                    .filter(col(\"municipio\").isNotNull()) # Foca em município/estado\n",
    "\n",
    "colunas_numericas_fill_zero = [\"casosNovos\", \"obitosNovos\", \"Recuperadosnovos\", \"emAcompanhamentoNovos\"]\n",
    "df_cleaned = df_filtered.na.fill(0, subset=colunas_numericas_fill_zero)\n",
    "\n",
    "# Criar features de tempo\n",
    "df_features = df_cleaned.withColumn(\"ano_data\", year(col(\"data\"))) \\\n",
    "                        .withColumn(\"mes_data\", month(col(\"data\"))) \\\n",
    "                        .withColumn(\"dia_semana_num\", dayofweek(col(\"data\"))) # 1=Domingo, 7=Sábado\n",
    "df_features.cache()\n",
    "\n",
    "# Mapear dia da semana para nomes\n",
    "df_final_base = df_features.withColumn(\"dia_semana_nome\",\n",
    "    when(col(\"dia_semana_num\") == 1, \"Domingo\")\n",
    "    .when(col(\"dia_semana_num\") == 2, \"Segunda\")\n",
    "    .when(col(\"dia_semana_num\") == 3, \"Terça\")\n",
    "    .when(col(\"dia_semana_num\") == 4, \"Quarta\")\n",
    "    .when(col(\"dia_semana_num\") == 5, \"Quinta\")\n",
    "    .when(col(\"dia_semana_num\") == 6, \"Sexta\")\n",
    "    .when(col(\"dia_semana_num\") == 7, \"Sábado\")\n",
    "    .otherwise(\"Nao Informado\")\n",
    ")\n",
    "df_final_base.cache()\n",
    "df_final_base.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'df_final_base' salvo com sucesso em: datasets_base/df_covid_tratado.parquet\n"
     ]
    }
   ],
   "source": [
    "caminho_para_salvar_parquet = \"datasets_base/df_covid_tratado.parquet\"\n",
    "\n",
    "# Salvar o DataFrame em Parquet\n",
    "# O modo 'overwrite' é útil durante o desenvolvimento para substituir o arquivo se ele já existir.\n",
    "df_final_base.write.mode(\"overwrite\").parquet(caminho_para_salvar_parquet)\n",
    "\n",
    "print(f\"DataFrame 'df_final_base' salvo com sucesso em: {caminho_para_salvar_parquet}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
